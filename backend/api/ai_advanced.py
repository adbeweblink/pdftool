"""
AI é€²éšåŠŸèƒ½ API - åˆç´„æ¯”å°ã€å€‹è³‡åµæ¸¬ã€è¡¨æ ¼æå–ã€æ™ºèƒ½é‡å‘½å
"""
import fitz
import base64
import json
import re
import httpx
from io import BytesIO
from fastapi import APIRouter, UploadFile, File, HTTPException, Form
from fastapi.responses import JSONResponse, StreamingResponse
from typing import List, Optional
from pydantic import BaseModel

from utils.file_handler import save_upload_file, generate_output_path

router = APIRouter()

# Gemini API è¨­å®š
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"


# ============ å·¥å…·å‡½å¼ ============
def extract_pdf_text(file_path, max_pages: int = 50) -> str:
    """æå– PDF å…¨éƒ¨æ–‡å­—"""
    pdf = fitz.open(file_path)
    text = ""

    for i, page in enumerate(pdf):
        if i >= max_pages:
            break
        text += f"\n=== ç¬¬ {i + 1} é  ===\n"
        text += page.get_text()

    pdf.close()
    return text


def extract_pdf_tables(file_path) -> list:
    """æå– PDF ä¸­çš„è¡¨æ ¼çµæ§‹"""
    pdf = fitz.open(file_path)
    all_tables = []

    for page_num, page in enumerate(pdf):
        # ä½¿ç”¨ PyMuPDF çš„è¡¨æ ¼æå–åŠŸèƒ½
        tables = page.find_tables()

        for table_num, table in enumerate(tables):
            table_data = {
                "page": page_num + 1,
                "table_index": table_num + 1,
                "rows": []
            }

            # æå–è¡¨æ ¼å…§å®¹
            for row in table.extract():
                table_data["rows"].append(row)

            if table_data["rows"]:
                all_tables.append(table_data)

    pdf.close()
    return all_tables


async def call_gemini_advanced(prompt: str, api_key: str, max_tokens: int = 4096) -> str:
    """å‘¼å« Gemini APIï¼ˆé€²éšç‰ˆï¼Œæ”¯æ´æ›´é•·è¼¸å‡ºï¼‰- BYOK æ¨¡å¼"""
    if not api_key:
        raise HTTPException(
            status_code=400,
            detail="âš ï¸ è«‹æä¾›æ‚¨çš„ Gemini API Key æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚"
        )

    async with httpx.AsyncClient(timeout=120.0) as client:
        try:
            response = await client.post(
                f"{GEMINI_API_URL}?key={api_key}",
                json={
                    "contents": [{
                        "parts": [{"text": prompt}]
                    }],
                    "generationConfig": {
                        "temperature": 0.3,  # ä½æº«åº¦ç¢ºä¿ç²¾ç¢ºæ€§
                        "maxOutputTokens": max_tokens,
                    }
                }
            )

            if response.status_code == 429:
                raise HTTPException(
                    status_code=429,
                    detail="â³ AI æœå‹™æš«æ™‚ç¹å¿™ï¼Œè«‹ç¨ç­‰å¹¾åˆ†é˜å¾Œå†è©¦ã€‚"
                )

            if response.status_code != 200:
                raise HTTPException(
                    status_code=response.status_code,
                    detail=f"âŒ AI æœå‹™ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œé‡è©¦ã€‚éŒ¯èª¤ä»£ç¢¼ï¼š{response.status_code}"
                )

            result = response.json()

            try:
                return result["candidates"][0]["content"]["parts"][0]["text"]
            except (KeyError, IndexError):
                raise HTTPException(
                    status_code=500,
                    detail="âŒ ç„¡æ³•è§£æ AI å›æ‡‰ï¼Œè«‹é‡è©¦ã€‚"
                )

        except httpx.TimeoutException:
            raise HTTPException(
                status_code=504,
                detail="â±ï¸ AI è™•ç†è¶…æ™‚ï¼Œè«‹å˜—è©¦è¼ƒå°çš„æ–‡ä»¶æˆ–ç¨å¾Œé‡è©¦ã€‚"
            )


# ============ åˆç´„æ¯”å° ============
@router.post("/compare")
async def compare_contracts(
    file1: UploadFile = File(..., description="ç¬¬ä¸€ä»½åˆç´„ PDF"),
    file2: UploadFile = File(..., description="ç¬¬äºŒä»½åˆç´„ PDF"),
    focus_areas: str = Form(
        "all",
        description="é—œæ³¨é‡é»ï¼šall=å…¨éƒ¨, terms=æ¢æ¬¾, numbers=é‡‘é¡æ—¥æœŸ, parties=ç•¶äº‹äºº"
    ),
    api_key: str = Form(..., description="æ‚¨çš„ Gemini API Key")
):
    """
    æ¯”å°å…©ä»½åˆç´„çš„å·®ç•°

    - ä¸Šå‚³å…©ä»½ PDF åˆç´„
    - AI åˆ†æä¸¦åˆ—å‡ºæ‰€æœ‰å·®ç•°
    - æ¨™ç¤ºé‡è¦è®Šæ›´ï¼ˆé‡‘é¡ã€æ—¥æœŸã€è²¬ä»»æ¢æ¬¾ç­‰ï¼‰
    """
    file1_path = await save_upload_file(file1, "ai")
    file2_path = await save_upload_file(file2, "ai")

    try:
        # æå–å…©ä»½æ–‡ä»¶çš„æ–‡å­—
        text1 = extract_pdf_text(file1_path)
        text2 = extract_pdf_text(file2_path)

        # å»ºç«‹æ¯”å°æç¤º
        focus_prompts = {
            "all": "æ‰€æœ‰å·®ç•°",
            "terms": "æ¢æ¬¾å’Œæ¢ä»¶çš„è®Šæ›´",
            "numbers": "é‡‘é¡ã€æ—¥æœŸã€æ•¸é‡çš„è®Šæ›´",
            "parties": "ç•¶äº‹äººã€ç°½ç½²è€…ã€è¯çµ¡è³‡è¨Šçš„è®Šæ›´"
        }
        focus = focus_prompts.get(focus_areas, focus_prompts["all"])

        prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„åˆç´„å¯©æŸ¥å°ˆå®¶ã€‚è«‹ä»”ç´°æ¯”å°ä»¥ä¸‹å…©ä»½åˆç´„ï¼Œæ‰¾å‡º{focus}ã€‚

## åˆç´„ Aï¼ˆåŸç‰ˆï¼‰ï¼š
{text1[:15000]}

## åˆç´„ Bï¼ˆæ–°ç‰ˆï¼‰ï¼š
{text2[:15000]}

## è«‹ä»¥ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š

### ğŸ“Š å·®ç•°ç¸½è¦½
- ç™¼ç¾ X è™•å·®ç•°
- é‡å¤§è®Šæ›´ï¼šX è™•
- ä¸€èˆ¬è®Šæ›´ï¼šX è™•

### ğŸ”´ é‡å¤§å·®ç•°ï¼ˆéœ€ç‰¹åˆ¥æ³¨æ„ï¼‰
å°æ–¼æ¯å€‹é‡å¤§å·®ç•°ï¼Œè«‹åˆ—å‡ºï¼š
1. **ä½ç½®**ï¼šç¬¬ X æ¢ / ç¬¬ X é 
2. **åŸç‰ˆå…§å®¹**ï¼šã€Œ...ã€
3. **æ–°ç‰ˆå…§å®¹**ï¼šã€Œ...ã€
4. **å½±éŸ¿è©•ä¼°**ï¼šé€™å€‹è®Šæ›´å¯èƒ½å¸¶ä¾†çš„å½±éŸ¿

### ğŸŸ¡ ä¸€èˆ¬å·®ç•°
åˆ—å‡ºå…¶ä»–è¼ƒå°çš„å·®ç•°

### ğŸ’¡ å¯©æŸ¥å»ºè­°
åŸºæ–¼å·®ç•°åˆ†æï¼Œçµ¦å‡ºå…·é«”å»ºè­°

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œç¢ºä¿è¼¸å‡ºæ¸…æ™°æ˜“è®€ã€‚
"""

        result = await call_gemini_advanced(prompt, api_key)

        return {
            "success": True,
            "comparison": result,
            "file1_name": file1.filename,
            "file2_name": file2.filename,
            "focus_areas": focus_areas
        }

    finally:
        file1_path.unlink(missing_ok=True)
        file2_path.unlink(missing_ok=True)


# ============ å€‹è³‡åµæ¸¬ ============
@router.post("/pii-detect")
async def detect_pii(
    file: UploadFile = File(...),
    action: str = Form("detect", description="å‹•ä½œï¼šdetect=åƒ…åµæ¸¬, redact=åµæ¸¬ä¸¦é®è”½"),
    pii_types: str = Form(
        "all",
        description="å€‹è³‡é¡å‹ï¼šall, id=èº«åˆ†è­‰, phone=é›»è©±, email=é›»å­éƒµä»¶, address=åœ°å€, account=å¸³è™Ÿ"
    ),
    api_key: str = Form(..., description="æ‚¨çš„ Gemini API Key")
):
    """
    åµæ¸¬ä¸¦é®è”½ PDF ä¸­çš„å€‹äººè³‡æ–™

    - æ”¯æ´èº«åˆ†è­‰å­—è™Ÿã€é›»è©±ã€Emailã€åœ°å€ã€éŠ€è¡Œå¸³è™Ÿ
    - å¯é¸æ“‡åƒ…åµæ¸¬æˆ–ç›´æ¥é®è”½
    """
    file_path = await save_upload_file(file, "ai")

    try:
        text = extract_pdf_text(file_path)

        # å®šç¾©å„é¡å€‹è³‡çš„æ­£å‰‡è¡¨é”å¼
        pii_patterns = {
            "id": {
                "name": "èº«åˆ†è­‰å­—è™Ÿ",
                "patterns": [
                    r'[A-Z][12]\d{8}',  # å°ç£èº«åˆ†è­‰
                    r'[A-Z][89]\d{8}',  # å¤–ç±å±…ç•™è­‰
                ]
            },
            "phone": {
                "name": "é›»è©±è™Ÿç¢¼",
                "patterns": [
                    r'09\d{2}[-\s]?\d{3}[-\s]?\d{3}',  # æ‰‹æ©Ÿ
                    r'0\d[-\s]?\d{3,4}[-\s]?\d{4}',    # å¸‚è©±
                    r'\+886[-\s]?\d{1,2}[-\s]?\d{3,4}[-\s]?\d{4}',  # åœ‹éš›æ ¼å¼
                ]
            },
            "email": {
                "name": "é›»å­éƒµä»¶",
                "patterns": [
                    r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',
                ]
            },
            "address": {
                "name": "åœ°å€",
                "patterns": [
                    r'[\u4e00-\u9fff]+[ç¸£å¸‚][\u4e00-\u9fff]+[å€é„‰é®å¸‚][\u4e00-\u9fff]+[è·¯è¡—å··å¼„è™Ÿæ¨“å®¤]+[\d\-ä¹‹\u4e00-\u9fff]*',
                ]
            },
            "account": {
                "name": "éŠ€è¡Œå¸³è™Ÿ",
                "patterns": [
                    r'\d{3,4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{2,4}',  # éŠ€è¡Œå¸³è™Ÿæ ¼å¼
                ]
            }
        }

        # é¸æ“‡è¦åµæ¸¬çš„é¡å‹
        if pii_types == "all":
            selected_types = pii_patterns.keys()
        else:
            selected_types = [t.strip() for t in pii_types.split(",")]

        # åŸ·è¡Œåµæ¸¬
        found_pii = []
        for pii_type in selected_types:
            if pii_type in pii_patterns:
                info = pii_patterns[pii_type]
                for pattern in info["patterns"]:
                    matches = re.findall(pattern, text)
                    for match in matches:
                        found_pii.append({
                            "type": pii_type,
                            "type_name": info["name"],
                            "value": match,
                            "masked": mask_pii(match, pii_type)
                        })

        # ä½¿ç”¨ AI è£œå……åµæ¸¬
        if found_pii or True:  # ç¸½æ˜¯ä½¿ç”¨ AI è£œå……
            prompt = f"""è«‹åˆ†æä»¥ä¸‹æ–‡ä»¶ï¼Œæ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„å€‹äººè³‡æ–™ï¼ˆPIIï¼‰ã€‚

æ–‡ä»¶å…§å®¹ï¼š
{text[:10000]}

è«‹æ‰¾å‡ºï¼š
1. å§“å
2. èº«åˆ†è­‰å­—è™Ÿ
3. é›»è©±è™Ÿç¢¼
4. é›»å­éƒµä»¶
5. åœ°å€
6. éŠ€è¡Œå¸³è™Ÿ
7. ä¿¡ç”¨å¡è™Ÿ
8. è­·ç…§è™Ÿç¢¼
9. å…¶ä»–æ•æ„Ÿå€‹è³‡

è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```json
{{
    "pii_items": [
        {{"type": "name", "value": "ç‹å°æ˜", "location": "ç¬¬1é "}},
        {{"type": "phone", "value": "0912-345-678", "location": "ç¬¬2é "}}
    ],
    "risk_level": "high/medium/low",
    "summary": "ç°¡çŸ­æ‘˜è¦"
}}
```
"""
            ai_result = await call_gemini_advanced(prompt, api_key)

            # å˜—è©¦è§£æ AI å›å‚³çš„ JSON
            try:
                # æå– JSON éƒ¨åˆ†
                json_match = re.search(r'```json\s*([\s\S]*?)\s*```', ai_result)
                if json_match:
                    ai_pii = json.loads(json_match.group(1))
                else:
                    ai_pii = json.loads(ai_result)
            except:
                ai_pii = {"pii_items": [], "summary": ai_result}

        # å¦‚æœéœ€è¦é®è”½
        output_file = None
        if action == "redact" and found_pii:
            output_file = await redact_pii_in_pdf(file_path, found_pii)

        result = {
            "success": True,
            "detected_count": len(found_pii),
            "regex_detected": found_pii,
            "ai_detected": ai_pii.get("pii_items", []),
            "risk_level": ai_pii.get("risk_level", "unknown"),
            "summary": ai_pii.get("summary", ""),
            "action": action
        }

        if output_file:
            result["download_url"] = f"/download/{output_file.name}"

        return result

    finally:
        file_path.unlink(missing_ok=True)


def mask_pii(value: str, pii_type: str) -> str:
    """é®è”½å€‹è³‡"""
    if pii_type == "id":
        return value[0] + "*" * 7 + value[-2:]
    elif pii_type == "phone":
        return value[:4] + "***" + value[-3:]
    elif pii_type == "email":
        parts = value.split("@")
        return parts[0][:2] + "***@" + parts[1]
    elif pii_type == "account":
        return value[:4] + "****" + value[-4:]
    else:
        if len(value) > 4:
            return value[:2] + "*" * (len(value) - 4) + value[-2:]
        return "*" * len(value)


async def redact_pii_in_pdf(file_path, pii_items: list):
    """åœ¨ PDF ä¸­é®è”½å€‹è³‡"""
    pdf = fitz.open(file_path)

    for page in pdf:
        for item in pii_items:
            value = item["value"]
            # æœå°‹ä¸¦é®è”½
            text_instances = page.search_for(value)
            for inst in text_instances:
                # ç”¨é»‘è‰²çŸ©å½¢é®è”½
                page.draw_rect(inst, color=(0, 0, 0), fill=(0, 0, 0))

    output_path = generate_output_path("redacted.pdf")
    pdf.save(str(output_path))
    pdf.close()

    return output_path


# ============ è¡¨æ ¼æå– ============
@router.post("/extract-table")
async def extract_tables(
    file: UploadFile = File(...),
    output_format: str = Form("json", description="è¼¸å‡ºæ ¼å¼ï¼šjson, csv, excel"),
    use_ai: bool = Form(True, description="æ˜¯å¦ä½¿ç”¨ AI å¢å¼·æå–"),
    api_key: str = Form(None, description="æ‚¨çš„ Gemini API Keyï¼ˆä½¿ç”¨ AI å¢å¼·æ™‚å¿…å¡«ï¼‰")
):
    """
    å¾ PDF æå–è¡¨æ ¼ä¸¦è½‰æ›ç‚ºçµæ§‹åŒ–è³‡æ–™

    - è‡ªå‹•åµæ¸¬ PDF ä¸­çš„è¡¨æ ¼
    - æ”¯æ´åŒ¯å‡ºç‚º JSONã€CSVã€Excel
    - AI å¢å¼·å¯è™•ç†è¤‡é›œè¡¨æ ¼
    """
    file_path = await save_upload_file(file, "ai")

    try:
        # å…ˆç”¨ PyMuPDF æå–è¡¨æ ¼
        tables = extract_pdf_tables(file_path)

        # å¦‚æœå•Ÿç”¨ AI å¢å¼·ï¼Œä½¿ç”¨ AI æ”¹å–„è¡¨æ ¼çµæ§‹
        if use_ai and tables:
            if not api_key:
                raise HTTPException(status_code=400, detail="âš ï¸ ä½¿ç”¨ AI å¢å¼·åŠŸèƒ½éœ€è¦æä¾›æ‚¨çš„ Gemini API Key")
            prompt = f"""è«‹åˆ†æä»¥ä¸‹å¾ PDF æå–çš„è¡¨æ ¼è³‡æ–™ï¼Œä¸¦ï¼š
1. ä¿®æ­£ä»»ä½•æå–éŒ¯èª¤
2. è­˜åˆ¥è¡¨é ­
3. çµ±ä¸€è³‡æ–™æ ¼å¼
4. åˆä½µè·¨é è¡¨æ ¼ï¼ˆå¦‚æœé©ç”¨ï¼‰

åŸå§‹è¡¨æ ¼è³‡æ–™ï¼š
{json.dumps(tables[:5], ensure_ascii=False, indent=2)}

è«‹ä»¥ JSON æ ¼å¼å›å‚³å„ªåŒ–å¾Œçš„è¡¨æ ¼ï¼š
```json
{{
    "tables": [
        {{
            "title": "è¡¨æ ¼æ¨™é¡Œï¼ˆå¦‚æœæœ‰ï¼‰",
            "headers": ["æ¬„ä½1", "æ¬„ä½2"],
            "rows": [
                ["å€¼1", "å€¼2"],
                ["å€¼3", "å€¼4"]
            ],
            "summary": "è¡¨æ ¼ç°¡è¿°"
        }}
    ]
}}
```
"""
            ai_result = await call_gemini_advanced(prompt, api_key)

            try:
                json_match = re.search(r'```json\s*([\s\S]*?)\s*```', ai_result)
                if json_match:
                    enhanced_tables = json.loads(json_match.group(1))
                    tables = enhanced_tables.get("tables", tables)
            except:
                pass  # ä½¿ç”¨åŸå§‹è¡¨æ ¼

        # å¦‚æœæ²’æœ‰åµæ¸¬åˆ°è¡¨æ ¼ï¼Œå˜—è©¦ç”¨ AI å¾æ–‡å­—ä¸­æå–
        if not tables and api_key:
            text = extract_pdf_text(file_path)
            prompt = f"""è«‹å¾ä»¥ä¸‹æ–‡ä»¶ä¸­æå–æ‰€æœ‰è¡¨æ ¼è³‡æ–™ã€‚å³ä½¿æ˜¯ç”¨ç©ºæ ¼æˆ– Tab å°é½Šçš„è³‡æ–™ä¹Ÿç®—è¡¨æ ¼ã€‚

æ–‡ä»¶å…§å®¹ï¼š
{text[:10000]}

è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼š
```json
{{
    "tables": [
        {{
            "title": "è¡¨æ ¼æ¨™é¡Œ",
            "headers": ["æ¬„ä½1", "æ¬„ä½2"],
            "rows": [["å€¼1", "å€¼2"]]
        }}
    ],
    "found_count": 1
}}
```

å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•è¡¨æ ¼ï¼Œå›å‚³ç©ºé™£åˆ—ã€‚
"""
            ai_result = await call_gemini_advanced(prompt, api_key)

            try:
                json_match = re.search(r'```json\s*([\s\S]*?)\s*```', ai_result)
                if json_match:
                    ai_tables = json.loads(json_match.group(1))
                    tables = ai_tables.get("tables", [])
            except:
                tables = []

        # æ ¹æ“šè¼¸å‡ºæ ¼å¼è™•ç†
        if output_format == "csv":
            # è½‰ç‚º CSV
            csv_content = ""
            for i, table in enumerate(tables):
                csv_content += f"# è¡¨æ ¼ {i + 1}\n"
                if "headers" in table:
                    csv_content += ",".join(str(h) for h in table["headers"]) + "\n"
                for row in table.get("rows", []):
                    csv_content += ",".join(str(cell) if cell else "" for cell in row) + "\n"
                csv_content += "\n"

            return StreamingResponse(
                iter([csv_content]),
                media_type="text/csv",
                headers={"Content-Disposition": "attachment; filename=tables.csv"}
            )

        elif output_format == "excel":
            # è½‰ç‚º Excelï¼ˆéœ€è¦ openpyxlï¼‰
            try:
                from openpyxl import Workbook

                wb = Workbook()

                for i, table in enumerate(tables):
                    if i == 0:
                        ws = wb.active
                        ws.title = f"è¡¨æ ¼{i + 1}"
                    else:
                        ws = wb.create_sheet(f"è¡¨æ ¼{i + 1}")

                    row_num = 1
                    if "headers" in table:
                        for col, header in enumerate(table["headers"], 1):
                            ws.cell(row=row_num, column=col, value=header)
                        row_num += 1

                    for row in table.get("rows", []):
                        for col, cell in enumerate(row, 1):
                            ws.cell(row=row_num, column=col, value=cell)
                        row_num += 1

                output = BytesIO()
                wb.save(output)
                output.seek(0)

                return StreamingResponse(
                    output,
                    media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    headers={"Content-Disposition": "attachment; filename=tables.xlsx"}
                )
            except ImportError:
                raise HTTPException(
                    status_code=500,
                    detail="âŒ Excel åŒ¯å‡ºéœ€è¦å®‰è£ openpyxlã€‚è«‹åŸ·è¡Œï¼špip install openpyxl"
                )

        # é è¨­ JSON æ ¼å¼
        return {
            "success": True,
            "table_count": len(tables),
            "tables": tables,
            "source_file": file.filename
        }

    finally:
        file_path.unlink(missing_ok=True)


# ============ æ™ºèƒ½é‡å‘½å ============
@router.post("/smart-rename")
async def smart_rename(
    file: UploadFile = File(...),
    naming_pattern: str = Form(
        "auto",
        description="å‘½åæ¨¡å¼ï¼šauto=è‡ªå‹•, date_title=æ—¥æœŸ_æ¨™é¡Œ, type_date=é¡å‹_æ—¥æœŸ"
    ),
    include_date: bool = Form(True, description="æ˜¯å¦åŒ…å«æ—¥æœŸ"),
    max_length: int = Form(50, description="æª”åæœ€å¤§é•·åº¦"),
    api_key: str = Form(..., description="æ‚¨çš„ Gemini API Key")
):
    """
    æ ¹æ“š PDF å…§å®¹æ™ºèƒ½ç”Ÿæˆæª”å

    - åˆ†ææ–‡ä»¶å…§å®¹
    - æå–é—œéµè³‡è¨Šï¼ˆæ—¥æœŸã€æ¨™é¡Œã€é¡å‹ï¼‰
    - ç”Ÿæˆæœ‰æ„ç¾©çš„æª”å
    """
    file_path = await save_upload_file(file, "ai")

    try:
        text = extract_pdf_text(file_path, max_pages=5)  # åªè®€å‰ 5 é 

        prompt = f"""è«‹åˆ†æä»¥ä¸‹æ–‡ä»¶ä¸¦æå–é—œéµè³‡è¨Šï¼Œç”¨æ–¼ç”Ÿæˆæª”æ¡ˆåç¨±ã€‚

æ–‡ä»¶å…§å®¹ï¼š
{text[:5000]}

è«‹æå–ä»¥ä¸‹è³‡è¨Šä¸¦ä»¥ JSON æ ¼å¼å›å‚³ï¼š
```json
{{
    "document_type": "åˆç´„/ç™¼ç¥¨/å ±å‘Š/ç°¡å ±/è¡¨å–®/ä¿¡ä»¶/å…¶ä»–",
    "title": "æ–‡ä»¶æ¨™é¡Œæˆ–ä¸»é¡Œ",
    "date": "YYYY-MM-DD æ ¼å¼çš„æ—¥æœŸï¼ˆå¦‚æœæœ‰ï¼‰",
    "parties": ["ç›¸é—œå–®ä½æˆ–äººå"],
    "key_identifier": "é—œéµè­˜åˆ¥ç¢¼ï¼ˆå¦‚åˆç´„ç·¨è™Ÿã€ç™¼ç¥¨è™Ÿç¢¼ç­‰ï¼‰",
    "suggested_names": [
        "å»ºè­°æª”å1",
        "å»ºè­°æª”å2",
        "å»ºè­°æª”å3"
    ]
}}
```

å‘½åè¦å‰‡ï¼š
1. ä½¿ç”¨ç¹é«”ä¸­æ–‡
2. ä¸è¦ä½¿ç”¨ç‰¹æ®Šå­—å…ƒï¼ˆ\ / : * ? " < > |ï¼‰
3. é•·åº¦ä¸è¶…é {max_length} å­—å…ƒ
4. è¦æœ‰è¾¨è­˜åº¦ï¼Œæ–¹ä¾¿æ—¥å¾Œæœå°‹
"""

        ai_result = await call_gemini_advanced(prompt, api_key)

        try:
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', ai_result)
            if json_match:
                doc_info = json.loads(json_match.group(1))
            else:
                doc_info = json.loads(ai_result)
        except:
            doc_info = {
                "document_type": "æ–‡ä»¶",
                "title": "æœªçŸ¥",
                "suggested_names": [file.filename]
            }

        # æ ¹æ“šå‘½åæ¨¡å¼ç”Ÿæˆæª”å
        suggested_names = doc_info.get("suggested_names", [])

        if naming_pattern == "date_title":
            date = doc_info.get("date", "")
            title = doc_info.get("title", "æ–‡ä»¶")
            if date and include_date:
                primary_name = f"{date}_{title}"
            else:
                primary_name = title
        elif naming_pattern == "type_date":
            doc_type = doc_info.get("document_type", "æ–‡ä»¶")
            date = doc_info.get("date", "")
            if date and include_date:
                primary_name = f"{doc_type}_{date}"
            else:
                primary_name = doc_type
        else:
            # auto æ¨¡å¼ä½¿ç”¨ AI å»ºè­°
            primary_name = suggested_names[0] if suggested_names else "æ–‡ä»¶"

        # æ¸…ç†æª”å
        primary_name = re.sub(r'[\\/:*?"<>|]', '_', primary_name)
        primary_name = primary_name[:max_length]

        return {
            "success": True,
            "original_name": file.filename,
            "suggested_name": primary_name + ".pdf",
            "alternative_names": [n + ".pdf" for n in suggested_names[:3]],
            "document_info": doc_info,
            "naming_pattern": naming_pattern
        }

    finally:
        file_path.unlink(missing_ok=True)


# ============ æ‰¹æ¬¡æ™ºèƒ½é‡å‘½å ============
@router.post("/batch-smart-rename")
async def batch_smart_rename(
    files: List[UploadFile] = File(...),
    naming_pattern: str = Form("auto"),
    api_key: str = Form(..., description="æ‚¨çš„ Gemini API Key")
):
    """
    æ‰¹æ¬¡æ™ºèƒ½é‡å‘½åå¤šå€‹ PDF
    """
    results = []

    for file in files:
        try:
            result = await smart_rename(
                file=file,
                naming_pattern=naming_pattern,
                api_key=api_key
            )
            results.append({
                "original": file.filename,
                "suggested": result["suggested_name"],
                "success": True
            })
        except Exception as e:
            results.append({
                "original": file.filename,
                "error": str(e),
                "success": False
            })

    return {
        "success": True,
        "total": len(files),
        "results": results
    }
